{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pageindex-rs vs PageIndex (Python) — Benchmark\n",
    "\n",
    "Measures **index build speed**, **node retrieval speed**, and **consistency** across document sizes.\n",
    "\n",
    "- 500 iterations per build benchmark\n",
    "- 1000 random lookups per retrieval benchmark\n",
    "- Reports mean, median, stdev, p95, p99, and max for every metric\n",
    "\n",
    "No LLM calls — pure parsing and retrieval only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import sys, time, random, statistics, re\n",
    "from pathlib import Path\n",
    "\n",
    "import pageindex_rs\n",
    "\n",
    "ORIG_PATH = \"/Volumes/ExtraStorage/PageIndexOriginal/PageIndex\"\n",
    "if ORIG_PATH not in sys.path:\n",
    "    sys.path.insert(0, ORIG_PATH)\n",
    "\n",
    "from pageindex.page_index_md import (\n",
    "    extract_nodes_from_markdown,\n",
    "    extract_node_text_content,\n",
    "    build_tree_from_nodes,\n",
    ")\n",
    "from pageindex.utils import write_node_id, format_structure, structure_to_list\n",
    "\n",
    "TESTS_DIR = Path(\"/Volumes/ExtraStorage/PageIndexRust/tests\")\n",
    "TESTS_DIR.mkdir(exist_ok=True)\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Benchmark Documents\n",
    "\n",
    "Pulls Wikipedia articles into documents of increasing size. Skip if files already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating small (~43 KB)...\n",
      "  Corporate finance: 43,082 chars\n",
      "  => bench_small.md: 42 KB\n",
      "Generating medium (~3 MB)...\n",
      "  Corporate finance: 43,082 chars\n",
      "  Investment banking: 32,507 chars\n",
      "  Mergers and acquisitions: 59,540 chars\n",
      "  Financial statement: 6,773 chars\n",
      "  Valuation (finance): 25,363 chars\n",
      "  Private equity: 62,795 chars\n",
      "  Hedge fund: 68,938 chars\n",
      "  Capital structure: 17,879 chars\n",
      "  Financial risk management: 47,198 chars\n",
      "  Stock market: 39,487 chars\n",
      "  => bench_medium.md: 395 KB\n",
      "Generating large (~10 MB)...\n",
      "  Corporate finance: 43,082 chars\n",
      "  Investment banking: 32,507 chars\n",
      "  Mergers and acquisitions: 59,540 chars\n",
      "  Financial statement: 6,773 chars\n",
      "  Valuation (finance): 25,363 chars\n",
      "  Private equity: 62,795 chars\n",
      "  Hedge fund: 68,938 chars\n",
      "  Capital structure: 17,879 chars\n",
      "  Financial risk management: 47,198 chars\n",
      "  Stock market: 39,487 chars\n",
      "  Bond (finance): 34,800 chars\n",
      "  Derivative (finance): 58,927 chars\n",
      "  Financial modeling: 12,131 chars\n",
      "  Leveraged buyout: 22,188 chars\n",
      "  Initial public offering: 19,277 chars\n",
      "  Venture capital: 56,708 chars\n",
      "  Asset management: 12,821 chars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pyo3lib/lib/python3.12/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /opt/miniconda3/envs/pyo3lib/lib/python3.12/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skipped Portfolio management: \"Portfolio management\" may refer to: \n",
      "Portfolio manager\n",
      "Investment management\n",
      "IT portfolio management\n",
      "Application portfolio management\n",
      "Product portfolio management\n",
      "Project management\n",
      "Project portfolio management\n",
      "  Portfolio management: 0 chars\n",
      "  Risk management: 42,215 chars\n",
      "  Financial regulation: 4,487 chars\n",
      "  Banking: 42,480 chars\n",
      "  Central bank: 44,079 chars\n",
      "  Monetary policy: 50,730 chars\n",
      "  Fiscal policy: 16,796 chars\n",
      "  Economic growth: 65,061 chars\n",
      "  Inflation: 66,912 chars\n",
      "  Interest rate: 24,457 chars\n",
      "  Foreign exchange market: 41,192 chars\n",
      "  Commodity market: 27,948 chars\n",
      "  Real estate investment trust: 32,676 chars\n",
      "  => bench_large.md: 1055 KB\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "def wiki_to_markdown(topic):\n",
    "    try:\n",
    "        page = wikipedia.page(topic, auto_suggest=False)\n",
    "        content = page.content\n",
    "        content = re.sub(r\"=== (.+?) ===\", r\"### \\\\1\", content)\n",
    "        content = re.sub(r\"== (.+?) ==\", r\"## \\\\1\", content)\n",
    "        return f\"# {page.title}\\\\n\\\\n{content}\"\n",
    "    except Exception as e:\n",
    "        print(f\"  Skipped {topic}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "TOPICS_SMALL = [\"Corporate finance\"]\n",
    "\n",
    "TOPICS_MEDIUM = [\n",
    "    \"Corporate finance\", \"Investment banking\", \"Mergers and acquisitions\",\n",
    "    \"Financial statement\", \"Valuation (finance)\", \"Private equity\",\n",
    "    \"Hedge fund\", \"Capital structure\", \"Financial risk management\", \"Stock market\",\n",
    "]\n",
    "\n",
    "TOPICS_LARGE = TOPICS_MEDIUM + [\n",
    "    \"Bond (finance)\", \"Derivative (finance)\", \"Financial modeling\",\n",
    "    \"Leveraged buyout\", \"Initial public offering\", \"Venture capital\",\n",
    "    \"Asset management\", \"Portfolio management\", \"Risk management\",\n",
    "    \"Financial regulation\", \"Banking\", \"Central bank\", \"Monetary policy\",\n",
    "    \"Fiscal policy\", \"Economic growth\", \"Inflation\", \"Interest rate\",\n",
    "    \"Foreign exchange market\", \"Commodity market\", \"Real estate investment trust\",\n",
    "]\n",
    "\n",
    "def build_and_save(topics, filename):\n",
    "    path = TESTS_DIR / filename\n",
    "    if path.exists():\n",
    "        print(f\"  {filename} exists ({path.stat().st_size/1024:.0f} KB) — skipping\")\n",
    "        return\n",
    "    combined = \"\"\n",
    "    for topic in topics:\n",
    "        md_text = wiki_to_markdown(topic)\n",
    "        combined += md_text + \"\\\\n\\\\n\"\n",
    "        print(f\"  {topic}: {len(md_text):,} chars\")\n",
    "    path.write_text(combined)\n",
    "    print(f\"  => {filename}: {path.stat().st_size/1024:.0f} KB\")\n",
    "\n",
    "print(\"Generating small (~43 KB)...\")\n",
    "build_and_save(TOPICS_SMALL,  \"bench_small.md\")\n",
    "print(\"Generating medium (~3 MB)...\")\n",
    "build_and_save(TOPICS_MEDIUM, \"bench_medium.md\")\n",
    "print(\"Generating large (~10 MB)...\")\n",
    "build_and_save(TOPICS_LARGE,  \"bench_large.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers ready\n"
     ]
    }
   ],
   "source": [
    "def percentile(data, p):\n",
    "    \"\"\"Return the p-th percentile of sorted data.\"\"\"\n",
    "    sorted_data = sorted(data)\n",
    "    k = (len(sorted_data) - 1) * p / 100\n",
    "    lo, hi = int(k), min(int(k) + 1, len(sorted_data) - 1)\n",
    "    return sorted_data[lo] + (sorted_data[hi] - sorted_data[lo]) * (k - lo)\n",
    "\n",
    "def stats(times):\n",
    "    return {\n",
    "        \"mean\":   statistics.mean(times),\n",
    "        \"median\": statistics.median(times),\n",
    "        \"stdev\":  statistics.stdev(times),\n",
    "        \"min\":    min(times),\n",
    "        \"p95\":    percentile(times, 95),\n",
    "        \"p99\":    percentile(times, 99),\n",
    "        \"max\":    max(times),\n",
    "    }\n",
    "\n",
    "def build_py_index(path):\n",
    "    content = Path(path).read_text()\n",
    "    node_list, md_lines = extract_nodes_from_markdown(content)\n",
    "    nodes_with_content = extract_node_text_content(node_list, md_lines)\n",
    "    tree = build_tree_from_nodes(nodes_with_content)\n",
    "    write_node_id(tree)\n",
    "    return format_structure(tree, order=[\"title\", \"node_id\", \"text\", \"line_num\", \"nodes\"])\n",
    "\n",
    "def find_py_node(tree, node_id):\n",
    "    for node in structure_to_list(tree):\n",
    "        if node[\"node_id\"] == node_id:\n",
    "            return node\n",
    "    return structure_to_list(tree)[0]\n",
    "\n",
    "def print_stats_table(label, rs, py):\n",
    "    speedups = {\n",
    "        k: py[k] / rs[k] if rs[k] > 0 else float('inf')\n",
    "        for k in [\"mean\", \"median\", \"stdev\", \"p95\", \"p99\", \"max\"]\n",
    "    }\n",
    "    print(f\"\\\\n  {label}\")\n",
    "    print(f\"  {'Metric':<10} {'Rust':>10} {'Python':>10} {'Speedup':>10}\")\n",
    "    print(f\"  {'-'*44}\")\n",
    "    for k in [\"mean\", \"median\", \"stdev\", \"p95\", \"p99\", \"max\"]:\n",
    "        print(f\"  {k:<10} {rs[k]:>9.4f}ms {py[k]:>9.4f}ms {speedups[k]:>9.2f}x\")\n",
    "\n",
    "print(\"Helpers ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Index Build Benchmark (500 iterations)\n",
    "\n",
    "Pure markdown parsing — no API calls.\n",
    "\n",
    "Each iteration builds a full tree from scratch including:\n",
    "- Header extraction\n",
    "- Text content extraction per node\n",
    "- Tree assembly\n",
    "- Node ID assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nBenchmarking bench_small.md (42 KB) — 500 iterations...\n",
      "\\n  bench_small.md (42 KB)\n",
      "  Metric           Rust     Python    Speedup\n",
      "  --------------------------------------------\n",
      "  mean          0.2067ms    0.1531ms      0.74x\n",
      "  median        0.1084ms    0.1495ms      1.38x\n",
      "  stdev         0.8347ms    0.0141ms      0.02x\n",
      "  p95           0.4845ms    0.1665ms      0.34x\n",
      "  p99           1.3354ms    0.2057ms      0.15x\n",
      "  max          17.4007ms    0.3755ms      0.02x\n",
      "\\nBenchmarking bench_medium.md (395 KB) — 500 iterations...\n",
      "\\n  bench_medium.md (395 KB)\n",
      "  Metric           Rust     Python    Speedup\n",
      "  --------------------------------------------\n",
      "  mean          0.8726ms    1.3693ms      1.57x\n",
      "  median        0.8452ms    1.3814ms      1.63x\n",
      "  stdev         0.0602ms    0.0534ms      0.89x\n",
      "  p95           0.9740ms    1.4553ms      1.49x\n",
      "  p99           1.1289ms    1.5107ms      1.34x\n",
      "  max           1.2899ms    1.6474ms      1.28x\n",
      "\\nBenchmarking bench_large.md (1055 KB) — 500 iterations...\n",
      "\\n  bench_large.md (1055 KB)\n",
      "  Metric           Rust     Python    Speedup\n",
      "  --------------------------------------------\n",
      "  mean          2.5485ms    4.2784ms      1.68x\n",
      "  median        2.5425ms    3.9597ms      1.56x\n",
      "  stdev         0.1039ms    2.7821ms     26.77x\n",
      "  p95           2.6854ms    4.1576ms      1.55x\n",
      "  p99           2.7807ms   20.9931ms      7.55x\n",
      "  max           3.7064ms   42.8897ms     11.57x\n",
      "\\nBuild benchmark complete\n"
     ]
    }
   ],
   "source": [
    "N_BUILD = 500\n",
    "build_results = {}\n",
    "\n",
    "for fname in [\"bench_small.md\", \"bench_medium.md\", \"bench_large.md\"]:\n",
    "    path = TESTS_DIR / fname\n",
    "    if not path.exists():\n",
    "        print(f\"Skipping {fname} — not found\")\n",
    "        continue\n",
    "\n",
    "    size_kb = path.stat().st_size / 1024\n",
    "    print(f\"\\\\nBenchmarking {fname} ({size_kb:.0f} KB) — {N_BUILD} iterations...\")\n",
    "\n",
    "    # Rust\n",
    "    rs_times = []\n",
    "    for _ in range(N_BUILD):\n",
    "        t0 = time.perf_counter()\n",
    "        pageindex_rs.PageIndex.from_file(fname, str(path))\n",
    "        rs_times.append((time.perf_counter() - t0) * 1000)\n",
    "\n",
    "    # Python\n",
    "    content = path.read_text()\n",
    "    py_times = []\n",
    "    for _ in range(N_BUILD):\n",
    "        t0 = time.perf_counter()\n",
    "        nl, ml = extract_nodes_from_markdown(content)\n",
    "        nc = extract_node_text_content(nl, ml)\n",
    "        t = build_tree_from_nodes(nc)\n",
    "        write_node_id(t)\n",
    "        py_times.append((time.perf_counter() - t0) * 1000)\n",
    "\n",
    "    rs_s = stats(rs_times)\n",
    "    py_s = stats(py_times)\n",
    "    build_results[fname] = {\"size_kb\": size_kb, \"rs\": rs_s, \"py\": py_s}\n",
    "    print_stats_table(f\"{fname} ({size_kb:.0f} KB)\", rs_s, py_s)\n",
    "\n",
    "print(\"\\\\nBuild benchmark complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Node Retrieval Benchmark (1000 lookups)\n",
    "\n",
    "Random node lookups across the full tree.\n",
    "\n",
    "- **Rust**: `HashMap` — O(1) lookup\n",
    "- **Python**: linear scan — O(n) — performance degrades as node count grows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nBuilding indexes for bench_small.md (42 KB)...\n",
      "  Node count: 28\n",
      "\\n  bench_small.md — 28 nodes\n",
      "  Metric           Rust     Python    Speedup\n",
      "  --------------------------------------------\n",
      "  mean          0.0072ms    0.0060ms      0.83x\n",
      "  median        0.0054ms    0.0048ms      0.90x\n",
      "  stdev         0.0098ms    0.0100ms      1.02x\n",
      "  p95           0.0198ms    0.0073ms      0.37x\n",
      "  p99           0.0428ms    0.0303ms      0.71x\n",
      "  max           0.2055ms    0.2320ms      1.13x\n",
      "\\nBuilding indexes for bench_medium.md (395 KB)...\n",
      "  Node count: 261\n",
      "\\n  bench_medium.md — 261 nodes\n",
      "  Metric           Rust     Python    Speedup\n",
      "  --------------------------------------------\n",
      "  mean          0.0119ms    0.0272ms      2.29x\n",
      "  median        0.0121ms    0.0270ms      2.23x\n",
      "  stdev         0.0055ms    0.0023ms      0.42x\n",
      "  p95           0.0210ms    0.0307ms      1.46x\n",
      "  p99           0.0227ms    0.0319ms      1.41x\n",
      "  max           0.0322ms    0.0591ms      1.83x\n",
      "\\nBuilding indexes for bench_large.md (1055 KB)...\n",
      "  Node count: 765\n",
      "\\n  bench_large.md — 765 nodes\n",
      "  Metric           Rust     Python    Speedup\n",
      "  --------------------------------------------\n",
      "  mean          0.0216ms    0.0686ms      3.18x\n",
      "  median        0.0201ms    0.0680ms      3.38x\n",
      "  stdev         0.0129ms    0.0051ms      0.39x\n",
      "  p95           0.0442ms    0.0764ms      1.73x\n",
      "  p99           0.0474ms    0.0827ms      1.74x\n",
      "  max           0.0762ms    0.1308ms      1.72x\n",
      "\\nRetrieval benchmark complete\n"
     ]
    }
   ],
   "source": [
    "N_RETRIEVAL = 1000\n",
    "retrieval_results = {}\n",
    "\n",
    "for fname in [\"bench_small.md\", \"bench_medium.md\", \"bench_large.md\"]:\n",
    "    path = TESTS_DIR / fname\n",
    "    if not path.exists():\n",
    "        print(f\"Skipping {fname} — not found\")\n",
    "        continue\n",
    "\n",
    "    size_kb = path.stat().st_size / 1024\n",
    "    print(f\"\\\\nBuilding indexes for {fname} ({size_kb:.0f} KB)...\")\n",
    "    rs_idx = pageindex_rs.PageIndex.from_file(fname, str(path))\n",
    "    py_tree = build_py_index(path)\n",
    "    node_count = len(rs_idx.node_ids())\n",
    "    print(f\"  Node count: {node_count}\")\n",
    "\n",
    "    rs_node_ids = rs_idx.node_ids()\n",
    "    py_node_ids = [n[\"node_id\"] for n in structure_to_list(py_tree)]\n",
    "\n",
    "    rs_times = []\n",
    "    for _ in range(N_RETRIEVAL):\n",
    "        nid = random.choice(rs_node_ids)\n",
    "        t0 = time.perf_counter()\n",
    "        rs_idx.get_node(nid)\n",
    "        rs_times.append((time.perf_counter() - t0) * 1000)\n",
    "\n",
    "    py_times = []\n",
    "    for _ in range(N_RETRIEVAL):\n",
    "        nid = random.choice(py_node_ids)\n",
    "        t0 = time.perf_counter()\n",
    "        find_py_node(py_tree, nid)\n",
    "        py_times.append((time.perf_counter() - t0) * 1000)\n",
    "\n",
    "    rs_s = stats(rs_times)\n",
    "    py_s = stats(py_times)\n",
    "    retrieval_results[fname] = {\"size_kb\": size_kb, \"node_count\": node_count, \"rs\": rs_s, \"py\": py_s}\n",
    "    print_stats_table(f\"{fname} — {node_count} nodes\", rs_s, py_s)\n",
    "\n",
    "print(\"\\\\nRetrieval benchmark complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "Consolidated view across all document sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "INDEX BUILD — 500 iterations per size\n",
      "==========================================================================================\n",
      "Document                 Size      Mean    Median     Stdev       p95       p99       Max    Speedup\n",
      "  (all times in ms)\n",
      "------------------------------------------------------------------------------------------\n",
      "  bench_small.md          42KB     0.207     0.108     0.835     0.485     1.335    17.401      0.74x  [Rust]\n",
      "  bench_small.md          42KB     0.153     0.149     0.014     0.166     0.206     0.376             [Python]\n",
      "\n",
      "  bench_medium.md        395KB     0.873     0.845     0.060     0.974     1.129     1.290      1.57x  [Rust]\n",
      "  bench_medium.md        395KB     1.369     1.381     0.053     1.455     1.511     1.647             [Python]\n",
      "\n",
      "  bench_large.md        1055KB     2.549     2.543     0.104     2.685     2.781     3.706      1.68x  [Rust]\n",
      "  bench_large.md        1055KB     4.278     3.960     2.782     4.158    20.993    42.890             [Python]\n",
      "\n",
      "==========================================================================================\n",
      "NODE RETRIEVAL — 1000 random lookups per size\n",
      "==========================================================================================\n",
      "Document               Nodes      Mean    Median     Stdev       p95       p99       Max    Speedup\n",
      "  (all times in ms)\n",
      "------------------------------------------------------------------------------------------\n",
      "  bench_small.md          28    0.0072    0.0054    0.0098    0.0198    0.0428    0.2055      0.83x  [Rust]\n",
      "  bench_small.md          28    0.0060    0.0048    0.0100    0.0073    0.0303    0.2320             [Python]\n",
      "\n",
      "  bench_medium.md        261    0.0119    0.0121    0.0055    0.0210    0.0227    0.0322      2.29x  [Rust]\n",
      "  bench_medium.md        261    0.0272    0.0270    0.0023    0.0307    0.0319    0.0591             [Python]\n",
      "\n",
      "  bench_large.md         765    0.0216    0.0201    0.0129    0.0442    0.0474    0.0762      3.18x  [Rust]\n",
      "  bench_large.md         765    0.0686    0.0680    0.0051    0.0764    0.0827    0.1308             [Python]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W = 90\n",
    "print(\"=\" * W)\n",
    "print(\"INDEX BUILD — 500 iterations per size\")\n",
    "print(\"=\" * W)\n",
    "print(f\"{'Document':<20} {'Size':>8}  {'Mean':>8}  {'Median':>8}  {'Stdev':>8}  {'p95':>8}  {'p99':>8}  {'Max':>8}  {'Speedup':>9}\")\n",
    "print(f\"  (all times in ms)\")\n",
    "print(\"-\" * W)\n",
    "for fname, r in build_results.items():\n",
    "    for impl, label in [(r['rs'], 'Rust'), (r['py'], 'Python')]:\n",
    "        speedup = r['py']['mean'] / r['rs']['mean']\n",
    "        sp_str = f\"{speedup:.2f}x\" if label == 'Rust' else \"\"\n",
    "        print(f\"  {fname:<18} {r['size_kb']:>7.0f}KB  {impl['mean']:>8.3f}  {impl['median']:>8.3f}  {impl['stdev']:>8.3f}  {impl['p95']:>8.3f}  {impl['p99']:>8.3f}  {impl['max']:>8.3f}  {sp_str:>9}  [{label}]\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * W)\n",
    "print(\"NODE RETRIEVAL — 1000 random lookups per size\")\n",
    "print(\"=\" * W)\n",
    "print(f\"{'Document':<20} {'Nodes':>7}  {'Mean':>8}  {'Median':>8}  {'Stdev':>8}  {'p95':>8}  {'p99':>8}  {'Max':>8}  {'Speedup':>9}\")\n",
    "print(f\"  (all times in ms)\")\n",
    "print(\"-\" * W)\n",
    "for fname, r in retrieval_results.items():\n",
    "    for impl, label in [(r['rs'], 'Rust'), (r['py'], 'Python')]:\n",
    "        speedup = r['py']['mean'] / r['rs']['mean']\n",
    "        sp_str = f\"{speedup:.2f}x\" if label == 'Rust' else \"\"\n",
    "        print(f\"  {fname:<18} {r['node_count']:>7}  {impl['mean']:>8.4f}  {impl['median']:>8.4f}  {impl['stdev']:>8.4f}  {impl['p95']:>8.4f}  {impl['p99']:>8.4f}  {impl['max']:>8.4f}  {sp_str:>9}  [{label}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyo3lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
